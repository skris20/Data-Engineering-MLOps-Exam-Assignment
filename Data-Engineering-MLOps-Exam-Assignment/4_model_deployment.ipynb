{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U hopsworks --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/550038\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> Deploy model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predict_example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_example.py\n",
    "import os\n",
    "import numpy as np\n",
    "import hsfs\n",
    "import joblib\n",
    "\n",
    "class Predict(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Initializes the serving state, reads a trained model\"\"\"\n",
    "        # load the trained model\n",
    "        self.model = joblib.load(os.environ[\"ARTIFACT_FILES_PATH\"] + \"/xgboost.pkl\")\n",
    "        print(\"Initialization Complete\")\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\" Serves a prediction request using a trained model\"\"\"\n",
    "        # Convert inputs to numpy array to handle batch predictions\n",
    "        inputs_array = np.array(inputs)\n",
    "        # Check if the input is a single instance or batch\n",
    "        if inputs_array.ndim == 1:\n",
    "            # Reshape if a single instance to match input shape expected by the model\n",
    "            inputs_array = inputs_array.reshape(1, -1)\n",
    "        # Make predictions\n",
    "        return self.model.predict(inputs_array).tolist()  # Return predictions as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100.000%|██████████| 885/885 elapsed<00:01 remaining<00:00\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataset_api = project.get_dataset_api()\n",
    "\n",
    "uploaded_file_path = dataset_api.upload(\"predict_example.py\", \"Models\", overwrite=True)\n",
    "predictor_script_path = os.path.join(\"/Projects\", project.name, uploaded_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file path: Models/predict_example.py\n",
      "Predictor script path: /Projects/skris20/Models/predict_example.py\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploaded file path:\", uploaded_file_path)\n",
    "print(\"Predictor script path:\", predictor_script_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Deployment with the same name already exists. Getting existing deployment...\n",
      "To create a new deployment choose a different name.\n",
      "Deployment: beerratingmodeldeployment1\n",
      "{\n",
      "    \"artifact_version\": 1,\n",
      "    \"batching_configuration\": {\n",
      "        \"batching_enabled\": false\n",
      "    },\n",
      "    \"created\": \"2024-05-07T03:52:59.000Z\",\n",
      "    \"creator\": \"Sebastian Kristensen\",\n",
      "    \"description\": null,\n",
      "    \"id\": 257029,\n",
      "    \"inference_logging\": \"NONE\",\n",
      "    \"model_framework\": \"PYTHON\",\n",
      "    \"model_name\": \"BeerRatingPredictionModel1\",\n",
      "    \"model_path\": \"/Projects/skris20/Models/BeerRatingPredictionModel1\",\n",
      "    \"model_server\": \"PYTHON\",\n",
      "    \"model_version\": 1,\n",
      "    \"name\": \"beerratingmodeldeployment1\",\n",
      "    \"predictor\": \"predict_example.py\",\n",
      "    \"predictor_resources\": {\n",
      "        \"limits\": {\n",
      "            \"cores\": 0.5,\n",
      "            \"gpus\": 0,\n",
      "            \"memory\": 1024\n",
      "        },\n",
      "        \"requests\": {\n",
      "            \"cores\": 0.2,\n",
      "            \"gpus\": 0,\n",
      "            \"memory\": 32\n",
      "        }\n",
      "    },\n",
      "    \"requested_instances\": 0,\n",
      "    \"serving_tool\": \"KSERVE\"\n",
      "}\n",
      "Deployment is already running\n"
     ]
    }
   ],
   "source": [
    "# Use the model name from the previous notebook.\n",
    "mr = project.get_model_registry()\n",
    "model = mr.get_model(\"BeerRatingPredictionModel1\", version=1)\n",
    "\n",
    "# Create and start the deployment\n",
    "deployment = model.deploy(\n",
    "    name=\"beerratingmodeldeployment1\",  # Give it a descriptive name\n",
    "    serving_tool=\"KSERVE\",  # Specify the serving tool (e.g., KSERVE)\n",
    "    script_file=predictor_script_path  # The path to your prediction script\n",
    ")\n",
    "\n",
    "print(\"Deployment: \" + deployment.name)\n",
    "deployment.describe()\n",
    "deployment.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOPS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
