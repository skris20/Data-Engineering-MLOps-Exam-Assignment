{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U hopsworks --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/550037\n",
      "2024-05-06 23:15:17,593 WARNING: using legacy validation callback\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> Deploy model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting predict_example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile predict_example.py\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "class Predict(object):\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the serving state, reads a trained model\"\"\"\n",
    "        # Ensure the model path is correct, use an environment variable or direct path\n",
    "        model_path = os.path.join(os.environ.get(\"ARTIFACT_FILES_PATH\", \"/mnt/models\"), \"xgboost.pkl\")\n",
    "        self.model = joblib.load(model_path)\n",
    "        print(\"Initialization Complete\")\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\"Serves a prediction request using a trained model\"\"\"\n",
    "        # Ensure inputs are correctly shaped\n",
    "        input_vector = np.array(inputs)\n",
    "        input_data = input_vector.reshape(1, -1)\n",
    "        return self.model.predict(input_data).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading: 100.000%|██████████| 719/719 elapsed<00:01 remaining<00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to the predictor script: /Projects/BDS24/Models/predict_example.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataset_api = project.get_dataset_api()\n",
    "uploaded_file_path = dataset_api.upload(\"predict_example.py\", \"Models\", overwrite=True)\n",
    "predictor_script_path = os.path.join(\"/Projects\", project.name, \"Models\", \"predict_example.py\")\n",
    "print(\"Path to the predictor script:\", predictor_script_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Deployment with the same name already exists. Getting existing deployment...\n",
      "To create a new deployment choose a different name.\n",
      "Deployment: beerratingmodeldeployment\n",
      "{\n",
      "    \"artifact_version\": 3,\n",
      "    \"batching_configuration\": {\n",
      "        \"batching_enabled\": false\n",
      "    },\n",
      "    \"created\": \"2024-05-06T21:49:09.000Z\",\n",
      "    \"creator\": \"Lasse Hylleberg Laursen\",\n",
      "    \"description\": null,\n",
      "    \"id\": 258051,\n",
      "    \"inference_logging\": \"NONE\",\n",
      "    \"model_framework\": \"PYTHON\",\n",
      "    \"model_name\": \"BeerRatingPredictionModel\",\n",
      "    \"model_path\": \"/Projects/BDS24/Models/BeerRatingPredictionModel\",\n",
      "    \"model_server\": \"PYTHON\",\n",
      "    \"model_version\": 1,\n",
      "    \"name\": \"beerratingmodeldeployment\",\n",
      "    \"predictor\": \"predict_example.py\",\n",
      "    \"predictor_resources\": {\n",
      "        \"limits\": {\n",
      "            \"cores\": 0.5,\n",
      "            \"gpus\": 0,\n",
      "            \"memory\": 1024\n",
      "        },\n",
      "        \"requests\": {\n",
      "            \"cores\": 0.2,\n",
      "            \"gpus\": 0,\n",
      "            \"memory\": 32\n",
      "        }\n",
      "    },\n",
      "    \"requested_instances\": 0,\n",
      "    \"serving_tool\": \"KSERVE\"\n",
      "}\n",
      "Deployment is already running\n"
     ]
    }
   ],
   "source": [
    "# Use the model name from the previous notebook.\n",
    "mr = project.get_model_registry()\n",
    "model = mr.get_model(\"BeerRatingPredictionModel\", version=1)\n",
    "\n",
    "# Create and start the deployment\n",
    "deployment = model.deploy(\n",
    "    name=\"beerratingmodeldeployment\",  # Give it a descriptive name\n",
    "    serving_tool=\"KSERVE\",  # Specify the serving tool (e.g., KSERVE)\n",
    "    script_file=predictor_script_path  # The path to your prediction script\n",
    ")\n",
    "\n",
    "print(\"Deployment: \" + deployment.name)\n",
    "deployment.describe()\n",
    "deployment.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOPS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
